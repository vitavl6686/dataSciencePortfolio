{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determening the characteristics of profitable mobile apps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to determine main characteristics of mobile applications leading to increasing the number of users.\n",
    "The results can be used in marketings purposes. \n",
    "\n",
    "The method used for determination is analysis of statistical data from Google Play (approximately 10.000 applications) and App Store (approximately 7000 applications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step is to open files containing the datasets and extract dataset from them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting android data\n",
    "android_file_open = open('googleplaystore.csv')\n",
    "android_file_read = reader(android_file_open)\n",
    "android_dataset = list(android_file_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting apple data\n",
    "apple_file_open = open('AppleStore.csv')\n",
    "apple_file_read = reader(apple_file_open)\n",
    "apple_dataset = list(apple_file_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial look at the datasets. Android."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we want to have an initial took at the Android dataset to determine the structure of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of columns:  13\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of columns: \", len(android_dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset columns' names:  ['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n"
     ]
    }
   ],
   "source": [
    "print(\"The dataset columns' names: \" , android_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of entries:  10841\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of entries: \", len(android_dataset) - 1) #the first row contains the columns' names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of an entry:  ['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n"
     ]
    }
   ],
   "source": [
    "print(\"Example of an entry: \", android_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial look at the datasets. Apple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will determine the structure of the Apple dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of columns:  16\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of columns: \", len(apple_dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset columns' names:  ['id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n"
     ]
    }
   ],
   "source": [
    "print(\"The dataset columns' names: \" , apple_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of entries:  7197\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of entries: \", len(apple_dataset) - 1) #the first row contains the columns' names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of an entry:  ['284882215', 'Facebook', '389879808', 'USD', '0.0', '2974676', '212', '3.5', '3.5', '95.0', '4+', 'Social Networking', '37', '1', '29', '1']\n"
     ]
    }
   ],
   "source": [
    "print(\"Example of an entry: \", apple_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will prepare the data for analysis.\n",
    "Preparation will consist of:\n",
    "* Removing duplicates\n",
    "* Removing invalid entries\n",
    "* Removing non-free applications\n",
    "* Removing non-English apps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several entries for the same application may lead to statistical errors. So, we will check the datasets for duplicates and remove those. \n",
    "\n",
    "We start with the counting of the number of duplicates. We consider two entries *duplicates* if they represent the same application (both entries have the same application name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes the dataset in a form of list and the index of the column that contains the name.\n",
    "# Returns the number of duplicates\n",
    "\n",
    "def number_of_duplicates(dataset: list, name_index: int) -> int:\n",
    "    uniques = set()\n",
    "    duplicates = 0\n",
    "    \n",
    "    for row in dataset[1:]:\n",
    "        app_name = row[name_index]\n",
    "        if  app_name in uniques:\n",
    "            duplicates += 1\n",
    "        else:\n",
    "            uniques.add(app_name)\n",
    "        \n",
    "    return duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Technique\n",
    "\n",
    "When we see the duplicate entries for one application, we would like to leave the entry with the maximum number of reviews because that's the newest one. \n",
    "To achieve that, we would create a dictionary called ```unique_entries``` the keys of which would be the unique names of the applications. Each value would be a diactionary of the number of reviews and the original row. \n",
    "\n",
    "We go through the dataset. When finding a duplicate of an entry for an application, we check if the number of reviews for in this entry larger than the saved one. If so, we update the saved data.\n",
    "However, if we encounter an entry for an app for the first time, we just save its data alongside the number of reviews to the unique_entries dictionary. \n",
    "\n",
    "At the end we go through the dictionary, adding all its entries to the list of unique elements. The cleaning from the duplicates is finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes the dataset in a form of list,the index of the column that contains the name\n",
    "# and the index of the column that contains the number of reviews.\n",
    "# Returns the initial dataset without the duplicates. \n",
    "# The order of rows is not guaranteed.\n",
    "\n",
    "\n",
    "def remove_duplicates(dataset: list, name_index: int, reviews_number_index: int) -> list:\n",
    "    unique_entries = dict()\n",
    "\n",
    "    for i in range(1, len(dataset)):\n",
    "        if dataset[i][name_index] not in unique_entries:\n",
    "            unique_entries[dataset[i][name_index]] = {'reviews': dataset[i][reviews_number_index], 'data': dataset[i]}\n",
    "    else:\n",
    "        if unique_entries[dataset[i][name_index]]['reviews'] < dataset[i][reviews_number_index]:\n",
    "            unique_entries[dataset[i][name_index]] = {'reviews': dataset[i][reviews_number_index], 'data': dataset[i]}\n",
    "            \n",
    "    unique_list = list()\n",
    "    unique_list.append(dataset[0])\n",
    "\n",
    "    for app in unique_entries:\n",
    "        unique_list.append(unique_entries[app]['data'])\n",
    "        \n",
    "    return unique_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Android dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many duplicates the Android dataset contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of duplicates in Android dataset is:  1181\n"
     ]
    }
   ],
   "source": [
    "duplicates = number_of_duplicates(android_dataset, 0)\n",
    "print('The number of duplicates in Android dataset is: ', duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the duplicates of the Android dataset.\n",
    "The name index is 0, the number of reviews column's index is 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_list_android = remove_duplicates(android_dataset, 0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique entries:  9660\n"
     ]
    }
   ],
   "source": [
    "# Number of unique items of the DS.\n",
    "resulting_length = len(unique_list_android) - 1\n",
    "print('The number of unique entries: ', resulting_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apple dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the Apple dataset contains duplicates. \n",
    "\n",
    "The two entries are duplicates if they have the same name of the applciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of duplicates in Apple dataset is:  2\n"
     ]
    }
   ],
   "source": [
    "duplicates = number_of_duplicates(apple_dataset, 1)\n",
    "print('The number of duplicates in Apple dataset is: ', duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same techniques of deleting duplicate rows for Apple dataset. \n",
    "The name column index is 1, the column index of the number of review is 5. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_list_apple = remove_duplicates(apple_dataset, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique entries in Apple dataset:  7195\n"
     ]
    }
   ],
   "source": [
    "# Number of unique items of the Apple DS.\n",
    "resulting_length = len(unique_list_apple) - 1\n",
    "print('The number of unique entries in Apple dataset: ', resulting_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing incorrect values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rows with wrong number of cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one example of invalid rows is the rows with wrong number of cells. \n",
    "Android dataset contains 13 columns and each rows must have 13 cells. \n",
    "Apple dataset contains 16 columns, so each row must have the length of 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each dataset without duiplicates we check if each rows contains correct number of cells and remove invalid rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a dataset with heading row.\n",
    "# Returns a dataset without rows with incorrect number of cells.\n",
    "\n",
    "def check_rows_length(dataset: list) -> list:\n",
    "    correct_rows = list()\n",
    "    correct_rows.append(dataset[0])\n",
    "    \n",
    "    number_of_cols = len(dataset[0])\n",
    "    \n",
    "    for row in dataset[1:]:\n",
    "        if len(row) == number_of_cols:\n",
    "            correct_rows.append(row)\n",
    "    \n",
    "    return correct_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Android\n",
    "correct_rows_android = check_rows_length(unique_list_android)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of removes entries:  1\n"
     ]
    }
   ],
   "source": [
    "removed_rows = len(unique_list_android) - len(correct_rows_android)\n",
    "print('The number of removes entries: ', removed_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apple\n",
    "correct_rows_apple = check_rows_length(unique_list_apple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of removes entries:  0\n"
     ]
    }
   ],
   "source": [
    "removed_rows = len(unique_list_apple) - len(correct_rows_apple)\n",
    "print('The number of removes entries: ', removed_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing non-English apps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our analysis is concerned with applications for English-speaking audience. So, we need to remove applications not designed for them. \n",
    "\n",
    "To do that, we will remove all applications that contain not-english, not punctuational and not-digits in its name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a function detecting if a name given is owned by a foreign app.\n",
    "It checks is the string contains more than three foreign symbols which could point to a foreign app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_foreign(text: str) -> bool:\n",
    "    count = 0\n",
    "    \n",
    "    for char in text:\n",
    "        if ord(char) > 127:\n",
    "            count += 1\n",
    "    \n",
    "    return count > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(contains_foreign('Instagram'))\n",
    "print(contains_foreign('çˆ±å¥‡è‰ºPPS -ã€Šæ¬¢ä¹é¢‚2ã€‹ç”µè§†å‰§çƒ­æ’­'))\n",
    "print(contains_foreign('Docs To Goâ„¢ Free Office Suite'))\n",
    "print(contains_foreign('Instachat ğŸ˜œ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
